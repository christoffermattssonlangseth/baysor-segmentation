{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa98c2ef",
   "metadata": {},
   "source": [
    "# Baysor Segmentation Diagnostics\n",
    "\n",
    "This notebook provides comprehensive diagnostics on Baysor segmentation outputs including:\n",
    "- Summary statistics of all segmentation runs\n",
    "- Cell-level QC metrics (transcript counts, gene diversity)\n",
    "- Spatial visualization of segmentation results\n",
    "- Unassigned transcript analysis\n",
    "- Comparison across multiple segmentation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e14163",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ec659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the root folder to search for Baysor outputs\n",
    "output_root = \"/Users/christoffer/Downloads/new_spinal_cord_data_CG\"\n",
    "\n",
    "# Verify the root exists\n",
    "if os.path.isdir(output_root):\n",
    "    print(f\"✓ Output root directory exists: {output_root}\")\n",
    "else:\n",
    "    print(f\"✗ Output root directory not found: {output_root}\")\n",
    "    print(\"Please update the output_root variable above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06f09e",
   "metadata": {},
   "source": [
    "## 2. Find and Scan Baysor Output Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f932c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segmentation_outputs(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively search for Baysor segmentation output folders.\n",
    "    Returns a list of directories containing segmentation.csv\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        # Look for segmentation.csv which indicates a Baysor output\n",
    "        if 'segmentation.csv' in files:\n",
    "            outputs.append(root)\n",
    "    \n",
    "    return sorted(outputs)\n",
    "\n",
    "# Find all segmentation outputs\n",
    "outputs = find_segmentation_outputs(output_root)\n",
    "print(f\"Found {len(outputs)} segmentation output(s)\\n\")\n",
    "\n",
    "for i, output_dir in enumerate(outputs, 1):\n",
    "    print(f\"{i}. {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e84abe",
   "metadata": {},
   "source": [
    "## 3. Load and Summarize All Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43729215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segmentation_data(output_dir):\n",
    "    \"\"\"\n",
    "    Load segmentation output files from a Baysor output directory.\n",
    "    Returns a dictionary with segmentation data and metadata.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    # Load main segmentation file\n",
    "    seg_path = os.path.join(output_dir, 'segmentation.csv')\n",
    "    if os.path.isfile(seg_path):\n",
    "        data['segmentation'] = pd.read_csv(seg_path)\n",
    "    \n",
    "    # Load cell stats if available\n",
    "    stats_path = os.path.join(output_dir, 'segmentation_cell_stats.csv')\n",
    "    if os.path.isfile(stats_path):\n",
    "        data['cell_stats'] = pd.read_csv(stats_path)\n",
    "    \n",
    "    # Load counts if available\n",
    "    counts_path = os.path.join(output_dir, 'segmentation_counts.tsv')\n",
    "    if os.path.isfile(counts_path):\n",
    "        data['counts'] = pd.read_csv(counts_path, sep='\\t')\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load all output data\n",
    "all_data = {}\n",
    "for output_dir in outputs:\n",
    "    all_data[output_dir] = load_segmentation_data(output_dir)\n",
    "\n",
    "print(f\"Loaded data for {len(all_data)} segmentation run(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f320496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_outputs(all_data):\n",
    "    \"\"\"\n",
    "    Create a summary dataframe of all Baysor outputs with key QC metrics.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for output_dir, data in all_data.items():\n",
    "        summary = {\n",
    "            'output_dir': output_dir,\n",
    "            'output_name': os.path.basename(output_dir),\n",
    "        }\n",
    "        \n",
    "        # Parse segmentation file\n",
    "        if 'segmentation' in data:\n",
    "            seg = data['segmentation']\n",
    "            summary['n_transcripts'] = len(seg)\n",
    "            \n",
    "            # Find cell column (various naming conventions)\n",
    "            cell_cols = [col for col in seg.columns if col.lower() in ['cell', 'cell_id', 'cellid', 'cell_index']]\n",
    "            if cell_cols:\n",
    "                cell_col = cell_cols[0]\n",
    "                # Count cells and unassigned transcripts\n",
    "                cell_ids = pd.to_numeric(seg[cell_col], errors='coerce')\n",
    "                assigned = cell_ids[cell_ids > 0]\n",
    "                summary['n_cells'] = assigned.nunique()\n",
    "                summary['n_assigned_transcripts'] = len(assigned)\n",
    "                summary['n_unassigned_transcripts'] = (cell_ids <= 0).sum()\n",
    "                summary['assigned_fraction'] = len(assigned) / len(cell_ids) if len(cell_ids) > 0 else 0\n",
    "            else:\n",
    "                summary['n_cells'] = np.nan\n",
    "                summary['n_assigned_transcripts'] = np.nan\n",
    "                summary['n_unassigned_transcripts'] = np.nan\n",
    "                summary['assigned_fraction'] = np.nan\n",
    "        \n",
    "        # Parse cell stats file\n",
    "        if 'cell_stats' in data:\n",
    "            stats = data['cell_stats']\n",
    "            summary['cell_stats_n_cells'] = len(stats)\n",
    "            \n",
    "            # Find transcript count column\n",
    "            count_cols = [col for col in stats.columns if col.lower() in ['n_transcripts', 'n_molecules', 'n_counts', 'n_genes']]\n",
    "            if count_cols and count_cols[0] != 'n_genes':\n",
    "                count_col = count_cols[0]\n",
    "                summary['mean_transcripts_per_cell'] = stats[count_col].mean()\n",
    "                summary['median_transcripts_per_cell'] = stats[count_col].median()\n",
    "                summary['min_transcripts_per_cell'] = stats[count_col].min()\n",
    "                summary['max_transcripts_per_cell'] = stats[count_col].max()\n",
    "        \n",
    "        # Check for counts file\n",
    "        counts_path = os.path.join(output_dir, 'segmentation_counts.tsv')\n",
    "        summary['has_counts_matrix'] = os.path.isfile(counts_path)\n",
    "        if summary['has_counts_matrix']:\n",
    "            file_size_mb = os.path.getsize(counts_path) / (1024**2)\n",
    "            summary['counts_matrix_size_mb'] = round(file_size_mb, 2)\n",
    "        \n",
    "        rows.append(summary)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "summary_df = summarize_outputs(all_data)\n",
    "print(\"\\n=== SEGMENTATION OUTPUT SUMMARY ===\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5640f9b",
   "metadata": {},
   "source": [
    "## 4. Detailed Analysis - Select an Output to Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which output to analyze in detail (index 0 for first output)\n",
    "selected_idx = 0\n",
    "\n",
    "if len(outputs) > 0:\n",
    "    selected_output = outputs[selected_idx]\n",
    "    selected_data = all_data[selected_output]\n",
    "    print(f\"Selected output: {selected_output}\")\n",
    "else:\n",
    "    print(\"No segmentation outputs found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the segmentation data\n",
    "if 'segmentation' in selected_data:\n",
    "    seg_df = selected_data['segmentation']\n",
    "    print(f\"Segmentation data shape: {seg_df.shape}\")\n",
    "    print(f\"\\nColumns: {list(seg_df.columns)}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    display(seg_df.head())\n",
    "else:\n",
    "    print(\"No segmentation data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c3d99d",
   "metadata": {},
   "source": [
    "## 5. Cell-Level Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce045b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'segmentation' in selected_data:\n",
    "    seg_df = selected_data['segmentation']\n",
    "    \n",
    "    # Find cell column\n",
    "    cell_cols = [col for col in seg_df.columns if col.lower() in ['cell', 'cell_id', 'cellid', 'cell_index']]\n",
    "    \n",
    "    if cell_cols:\n",
    "        cell_col = cell_cols[0]\n",
    "        cell_ids = pd.to_numeric(seg_df[cell_col], errors='coerce')\n",
    "        \n",
    "        # Analyze assigned cells\n",
    "        assigned_mask = cell_ids > 0\n",
    "        assigned_ids = cell_ids[assigned_mask]\n",
    "        \n",
    "        print(f\"Cell Assignment Summary:\")\n",
    "        print(f\"  Total transcripts: {len(seg_df):,}\")\n",
    "        print(f\"  Assigned transcripts: {assigned_mask.sum():,}\")\n",
    "        print(f\"  Unassigned transcripts: {(~assigned_mask).sum():,}\")\n",
    "        print(f\"  % Assigned: {100 * assigned_mask.sum() / len(seg_df):.1f}%\")\n",
    "        print(f\"  Number of cells: {assigned_ids.nunique():,}\")\n",
    "        \n",
    "        # Per-cell statistics\n",
    "        per_cell_stats = seg_df[assigned_mask].groupby(cell_col).size().reset_index(name='n_transcripts')\n",
    "        \n",
    "        print(f\"\\n  Transcripts per cell:\")\n",
    "        print(f\"    Mean: {per_cell_stats['n_transcripts'].mean():.1f}\")\n",
    "        print(f\"    Median: {per_cell_stats['n_transcripts'].median():.1f}\")\n",
    "        print(f\"    Min: {per_cell_stats['n_transcripts'].min()}\")\n",
    "        print(f\"    Max: {per_cell_stats['n_transcripts'].max()}\")\n",
    "        print(f\"    Std: {per_cell_stats['n_transcripts'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea5556",
   "metadata": {},
   "source": [
    "## 6. Spatial Distribution of Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'segmentation' in selected_data:\n",
    "    seg_df = selected_data['segmentation']\n",
    "    \n",
    "    # Find spatial columns\n",
    "    x_cols = [col for col in seg_df.columns if col.lower() in ['x', 'global_x', 'x_coord', 'x_position']]\n",
    "    y_cols = [col for col in seg_df.columns if col.lower() in ['y', 'global_y', 'y_coord', 'y_position']]\n",
    "    cell_cols = [col for col in seg_df.columns if col.lower() in ['cell', 'cell_id', 'cellid', 'cell_index']]\n",
    "    \n",
    "    if x_cols and y_cols and cell_cols:\n",
    "        x_col, y_col, cell_col = x_cols[0], y_cols[0], cell_cols[0]\n",
    "        \n",
    "        # Create spatial plot\n",
    "        plot_df = seg_df[[x_col, y_col, cell_col]].copy()\n",
    "        plot_df['cell_assigned'] = pd.to_numeric(plot_df[cell_col], errors='coerce') > 0\n",
    "        \n",
    "        fig = px.scatter(\n",
    "            plot_df,\n",
    "            x=x_col,\n",
    "            y=y_col,\n",
    "            color='cell_assigned',\n",
    "            color_discrete_map={True: 'blue', False: 'red'},\n",
    "            opacity=0.6,\n",
    "            labels={'cell_assigned': 'Assigned'},\n",
    "            title='Spatial Distribution of Assigned vs Unassigned Transcripts',\n",
    "            height=600\n",
    "        )\n",
    "        fig.update_layout(hovermode='closest')\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"Spatial columns (x, y, cell) not found in segmentation file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe85ff3",
   "metadata": {},
   "source": [
    "## 7. Transcript Count Distribution per Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'segmentation' in selected_data:\n",
    "    seg_df = selected_data['segmentation']\n",
    "    cell_cols = [col for col in seg_df.columns if col.lower() in ['cell', 'cell_id', 'cellid', 'cell_index']]\n",
    "    \n",
    "    if cell_cols:\n",
    "        cell_col = cell_cols[0]\n",
    "        cell_ids = pd.to_numeric(seg_df[cell_col], errors='coerce')\n",
    "        assigned_mask = cell_ids > 0\n",
    "        \n",
    "        # Get transcript counts per cell\n",
    "        per_cell_counts = seg_df[assigned_mask].groupby(cell_col).size()\n",
    "        \n",
    "        # Create histogram\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Histogram(\n",
    "            x=per_cell_counts.values,\n",
    "            nbinsx=50,\n",
    "            name='Transcript count',\n",
    "            marker_color='rgba(55, 83, 109, 0.7)'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Distribution of Transcripts per Cell',\n",
    "            xaxis_title='Transcripts per Cell',\n",
    "            yaxis_title='Number of Cells',\n",
    "            height=400,\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57455f9",
   "metadata": {},
   "source": [
    "## 8. Gene Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e92061",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'segmentation' in selected_data:\n",
    "    seg_df = selected_data['segmentation']\n",
    "    \n",
    "    # Find gene column\n",
    "    gene_cols = [col for col in seg_df.columns if col.lower() in ['gene', 'gene_name', 'gene_id']]\n",
    "    \n",
    "    if gene_cols:\n",
    "        gene_col = gene_cols[0]\n",
    "        \n",
    "        # Get top genes\n",
    "        gene_counts = seg_df[gene_col].value_counts().head(20)\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=gene_counts.index,\n",
    "            x=gene_counts.values,\n",
    "            orientation='h',\n",
    "            marker_color='rgba(55, 83, 109, 0.7)'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Top 20 Most Abundant Genes',\n",
    "            xaxis_title='Transcript Count',\n",
    "            yaxis_title='Gene',\n",
    "            height=500,\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        print(f\"\\nGene Statistics:\")\n",
    "        print(f\"  Total unique genes: {seg_df[gene_col].nunique():,}\")\n",
    "        print(f\"  Total transcripts: {len(seg_df):,}\")\n",
    "        print(f\"  Mean transcripts per gene: {len(seg_df) / seg_df[gene_col].nunique():.1f}\")\n",
    "    else:\n",
    "        print(\"Gene column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f282c39",
   "metadata": {},
   "source": [
    "## 9. Cell Statistics Summary (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cell_stats' in selected_data:\n",
    "    cell_stats_df = selected_data['cell_stats']\n",
    "    print(f\"Cell statistics shape: {cell_stats_df.shape}\")\n",
    "    print(f\"\\nColumns: {list(cell_stats_df.columns)}\")\n",
    "    print(f\"\\nStatistics summary:\")\n",
    "    display(cell_stats_df.describe())\n",
    "else:\n",
    "    print(\"No cell statistics file found for this output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da87a9c",
   "metadata": {},
   "source": [
    "## 10. Export Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad505b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary dataframe to CSV\n",
    "summary_path = os.path.join(output_root, 'baysor_outputs_summary.csv')\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"✓ Summary saved to: {summary_path}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Total segmentation outputs found: {len(outputs)}\")\n",
    "print(f\"\\nKey metrics:\")\n",
    "if 'n_transcripts' in summary_df.columns and len(summary_df) > 0:\n",
    "    print(f\"  Total transcripts (all runs): {summary_df['n_transcripts'].sum():,}\")\n",
    "if 'n_cells' in summary_df.columns:\n",
    "    print(f\"  Total cells (all runs): {summary_df['n_cells'].sum():,.0f}\")\n",
    "if 'assigned_fraction' in summary_df.columns:\n",
    "    print(f\"  Average assignment rate: {summary_df['assigned_fraction'].mean():.1%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
