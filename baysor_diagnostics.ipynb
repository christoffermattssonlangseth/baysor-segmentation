{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baysor Output Diagnostics\n",
        "\n",
        "This notebook scans for Baysor output folders and summarizes key QC metrics from\n",
        "`segmentation.csv`, `segmentation_cell_stats.csv`, and `segmentation_counts.tsv`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configure the output root\n",
        "Set this to the directory where Baysor outputs live. `.` searches the repo recursively.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "output_root = \".\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load packages\n",
        "If these are missing, install them with `Pkg.add(\"CSV\")` etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "using CSV\n",
        "using DataFrames\n",
        "using Statistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Find Baysor output folders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "function find_outputs(root::AbstractString)\n",
        "    dirs = String[]\n",
        "    for (dir, _, files) in walkdir(root)\n",
        "        if \"segmentation.csv\" in files\n",
        "            push!(dirs, dir)\n",
        "        end\n",
        "    end\n",
        "    sort!(dirs)\n",
        "    return dirs\n",
        "end\n",
        "\n",
        "outputs = find_outputs(output_root)\n",
        "println(\"Found $(length(outputs)) outputs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summarize outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "function pick_column(names_vec, candidates)\n",
        "    lower = Dict(lowercase(String(n)) => n for n in names_vec)\n",
        "    for cand in candidates\n",
        "        n = get(lower, cand, nothing)\n",
        "        if n !== nothing\n",
        "            return n\n",
        "        end\n",
        "    end\n",
        "    return nothing\n",
        "end\n",
        "\n",
        "function read_segmentation_summary(path)\n",
        "    df = CSV.read(path, DataFrame)\n",
        "    n_transcripts = nrow(df)\n",
        "    cell_col = pick_column(names(df), [\"cell\", \"cell_id\", \"cellid\", \"cell_index\"])\n",
        "    if cell_col === nothing\n",
        "        return (n_transcripts=n_transcripts, n_cells=missing, unassigned_frac=missing)\n",
        "    end\n",
        "    cell_raw = df[!, cell_col]\n",
        "    cell_ids = [tryparse(Int, string(x)) for x in cell_raw]\n",
        "    valid = [c for c in cell_ids if c !== nothing]\n",
        "    if isempty(valid)\n",
        "        return (n_transcripts=n_transcripts, n_cells=missing, unassigned_frac=missing)\n",
        "    end\n",
        "    n_cells = length(unique(filter(>(0), valid)))\n",
        "    unassigned = count(c -> c <= 0, valid)\n",
        "    unassigned_frac = unassigned / length(valid)\n",
        "    return (n_transcripts=n_transcripts, n_cells=n_cells, unassigned_frac=unassigned_frac)\n",
        "end\n",
        "\n",
        "function read_cell_stats_summary(path)\n",
        "    df = CSV.read(path, DataFrame)\n",
        "    cell_col = pick_column(names(df), [\"cell\", \"cell_id\", \"cellid\", \"cell_index\"])\n",
        "    count_col = pick_column(names(df), [\"n_transcripts\", \"n_molecules\", \"n_counts\", \"n_genes\"])\n",
        "    n_cells = cell_col === nothing ? nrow(df) : length(unique(df[!, cell_col]))\n",
        "    mean_counts = count_col === nothing ? missing : mean(skipmissing(df[!, count_col]))\n",
        "    median_counts = count_col === nothing ? missing : median(skipmissing(df[!, count_col]))\n",
        "    return (n_cells=n_cells, mean_counts=mean_counts, median_counts=median_counts)\n",
        "end\n",
        "\n",
        "function file_size_mb(path)\n",
        "    return round(stat(path).size / 1024^2; digits=2)\n",
        "end\n",
        "\n",
        "rows = NamedTuple[]\n",
        "for dir in outputs\n",
        "    seg_path = joinpath(dir, \"segmentation.csv\")\n",
        "    stats_path = joinpath(dir, \"segmentation_cell_stats.csv\")\n",
        "    counts_path = joinpath(dir, \"segmentation_counts.tsv\")\n",
        "\n",
        "    seg = read_segmentation_summary(seg_path)\n",
        "    stats = isfile(stats_path) ? read_cell_stats_summary(stats_path) : (n_cells=missing, mean_counts=missing, median_counts=missing)\n",
        "    counts_size = isfile(counts_path) ? file_size_mb(counts_path) : missing\n",
        "\n",
        "    push!(rows, (\n",
        "        output_dir=dir,\n",
        "        n_transcripts=seg.n_transcripts,\n",
        "        n_cells=seg.n_cells,\n",
        "        unassigned_frac=seg.unassigned_frac,\n",
        "        cell_stats_cells=stats.n_cells,\n",
        "        mean_counts=stats.mean_counts,\n",
        "        median_counts=stats.median_counts,\n",
        "        counts_size_mb=counts_size,\n",
        "        has_counts=isfile(counts_path)\n",
        "    ))\n",
        "end\n",
        "\n",
        "summary = DataFrame(rows)\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Inspect a single output directory\n",
        "Pick one output folder to dig deeper. This previews a few rows and gives a simple\n",
        "per-cell transcript count summary if a cell column is available.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "selected_output = isempty(outputs) ? nothing : first(outputs)\n",
        "selected_output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if selected_output === nothing\n",
        "    println(\"No outputs found. Check output_root.\")\n",
        "else\n",
        "    seg_path = joinpath(selected_output, \"segmentation.csv\")\n",
        "    seg_preview = CSV.read(seg_path, DataFrame; limit=5)\n",
        "    display(seg_preview)\n",
        "\n",
        "    cell_col = pick_column(names(seg_preview), [\"cell\", \"cell_id\", \"cellid\", \"cell_index\"])\n",
        "    if cell_col === nothing\n",
        "        println(\"No cell column found in segmentation.csv\")\n",
        "    else\n",
        "        seg_full = CSV.read(seg_path, DataFrame)\n",
        "        cell_ids = [tryparse(Int, string(x)) for x in seg_full[!, cell_col]]\n",
        "        valid = filter(c -> c !== nothing && c > 0, cell_ids)\n",
        "        if isempty(valid)\n",
        "            println(\"No assigned cells detected in segmentation.csv\")\n",
        "        else\n",
        "            per_cell = combine(groupby(DataFrame(cell=valid), :cell), nrow => :n_transcripts)\n",
        "            println(\"Per-cell transcript count summary (assigned cells only):\")\n",
        "            display(describe(per_cell))\n",
        "        end\n",
        "    end\n",
        "end\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Baysor-16-Threads 1.10.9",
      "language": "julia",
      "name": "baysor-16-threads-1.10"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}